# ADR 0003 — Governance للـShadow LLM

**التاريخ:** 2025-09-30

**الحالة:** مقترح

## السياق

يتطلب دمج Shadow LLM المحسن في نظام Zebra سياسة حوكمة صارمة لضمان أن توصياته آمنة وموثوقة ويمكن تتبعها. نظرًا لأن مخرجات LLM يمكن أن تكون غير حتمية وتحتمل أخطاء، فمن الضروري وجود ضوابط قوية قبل أن تؤثر على أي قرار أو إجراء تلقائي.

## القرار

1.  **تصنيف التوصيات:** أي توصية مُصنَّفة "Actionable" من Shadow LLM تتطلب **مراجعة بشرية موثقة** قبل التنفيذ. لا يُسمح بالتنفيذ التلقائي الكامل في هذه المرحلة.

2.  **تسجيل التدقيق (Audit Log):** تُخزَّن كل استدعاءات LLM كـ **audit events** في مخزن بيانات آمن (مثل Supabase أو سجلات مخصصة). يجب أن يحتوي كل سجل على الأقل على:
    *   `prompt_hash`: هاش للمدخل النصي (لتجنب تخزين البيانات الحساسة).
    *   `model_id`: معرف النموذج المستخدم (e.g., `gpt-4-turbo-2024-04-09`).
    *   `timestamp`: وقت الاستدعاء.
    *   `response_hash`: هاش للاستجابة.
    *   `decision`: التصنيف الذي تم إعطاؤه للنتيجة (Informational, Suggested, Actionable).
    *   `review_status`: حالة المراجعة (Pending, Approved, Rejected).

3.  **منع الأوامر المباشرة:** يُمنع منعًا باتًا تنفيذ أي أوامر نظام (shell, infrastructure commands) أو استدعاءات API حساسة مباشرة من مخرجات LLM. يجب أن تمر جميع الإجراءات المقترحة عبر طبقة وسيطة تتحقق من صحة الأمر وتصريح التنفيذ.

4.  **تصفية المحتوى (Content Filtering):** تُطبَّق قواعد تصفية تلقائية على كل من المدخلات والمخرجات:
    *   **إخفاء PII:** يجب إخفاء أو تحييد أي معلومات تعريف شخصية (PII) قبل إرسالها في prompt.
    *   **فحص السلامة:** يجب فحص المخرجات للتأكد من عدم وجود بيانات اعتماد، أو رموز ضارة، أو محتوى غير لائق.

## التحققات التلقائية (Automated Checks)

قبل عرض أي توصية للمراجعة البشرية، يجب أن تجتاز الفحوصات التلقائية التالية:

*   **التحقق من صحة المخطط (JSON Schema Validation):** إذا كان من المتوقع أن يكون الإخراج بصيغة JSON، فيجب التحقق من صحته مقابل مخطط محدد مسبقًا.
*   **مرشح السلامة (Safety Filter):** التحقق من عدم وجود كلمات أو أنماط محظورة.
*   **عتبة الثقة (Confidence Threshold):** إذا كان النموذج يرجع درجة ثقة، فيجب أن تتجاوز هذه الدرجة عتبة محددة مسبقًا (e.g., `confidence >= 0.8`).

## المبررات

*   **الأمان والتحكم:** يضمن هذا النهج أن القرارات النهائية تظل تحت السيطرة البشرية، مما يقلل من مخاطر الأخطاء الكارثية.
*   **المساءلة والتتبع:** يوفر سجل التدقيق الكامل القدرة على تتبع جميع القرارات التي تأثرت بـ LLM، وهو أمر ضروري لتصحيح الأخطاء والتحسين المستمر.
*   **منع إساءة الاستخدام:** تمنع سياسة "منع الأوامر المباشرة" وتصفية المحتوى الهجمات المحتملة أو السلوك غير المتوقع.

## العواقب

*   **زيادة الاعتماد على المراجعة البشرية:** كما هو الحال مع ADR-0002، يتطلب هذا النهج تدخلاً بشريًا، مما قد يبطئ من سرعة اتخاذ القرار.
*   **تعقيد إضافي في البنية التحتية:** يتطلب تنفيذ سجل التدقيق وتصفية المحتوى مكونات برمجية إضافية.
*   **الحاجة إلى تطوير مرشحات قوية:** يتطلب إنشاء مرشحات فعالة للـ PII والسلامة جهدًا مستمرًا وصيانة.